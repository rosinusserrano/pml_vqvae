The following sections will discuss the results of our baseline experiments, further ideas for the project, and real-world applications of the project.

\subsection{Baseline Experiments}\label{subsec:baseline-results}
    We present some results of our baseline training runs. We did an examplarily training for 10 epochs on a subset of ImageNet to see that it converges. The subset contained 100.000 images with 1000 samples per class. See ... for the full configuration details.
    
    \subsubsection{Autoencoder}\label{subsubsec:autoencoder}
        We were able to show that our implementation of an \ac{ae} is able to reconstruct images from the ImageNet dataset. W

        For this trainig, we used a latent dimension of 32x32x2 pixels, which means 4 bits per pixel for an 128x128x3 input images. That is a compression rate of 4,7 \% compared to the original image size.

        We are surprised by the results of our basic \ac{ae} and its capability to reconstruct images. Even with a realitively small latent dimension and only 10 epochs of training it is able to reconstruct images with a satifiying human percetiple quality.
        
        

\subsubsection{Class Differences}\label{subsubsec:class-differences}
\subsection{Further Ideas for the Project}\label{subsec:further-ideas}
\subsection{Real World Use of the Datasets}\label{subsec:real-world-applications}
\ac{cifar} and ImageNet have been around for one and a half decades.
Overall, their use-case has shifted from being the cutting edge datasets to train on to
more of a dataset for experiments and benchmarks.

The outstanding status of ImageNet in its early days gets apparent when looking at AlexNet~\cite{AlexNet}.
The paper on training a \ac{cnn} on ImageNet with \ac{GPU}s has been cited a staggering 166 thousand times as of the
time of this report and is seen as one the starting points of the rise of \ac{dnn}.

Today, the newest (text-based) image generation networks use much bigger datasets, with sample sizes stretching into
the billions.
One prominent example of such datasets is LAION-5B described by~\cite{laion5b}, which is for example used by Stable
Diffusion based on the work of~\cite{stable_diff}.
When examining this paper in greater detail, the continued relevance of ImageNet becomes clear.
First, the dataset is used to train experimental networks, which would be prohibitively expensive to train on larger,
modern datasets.
Furthermore, metrics like the \ac{fid}, also introduced in Section~\ref{sec:evaluation-metrics}, are used calculated on
ImageNet, further underscoring its importance for research.

Similar observations can be made for \ac{cifar-10}, but its limited resolution makes it less suitable for
benchmarking modern approaches to image generation.

Given these observations, while we anticipate producing some convincing results with our final model,
we do not expect to match the visual fidelity achieved by state-of-the-art image generation models.


\vskip 1em
\textbf{A Note on Overfitting:}
Overfitting refers to the phenomenon where a model starts to memorize the training data instead of learning useful
features, in turn not generalizing well to unseen data.

While theoretically, this may very well be an issue with \ac{ae} and \ac{vae}, we have not experienced this happening
yet with either when training with adequate training-set sizes.
This is likely due to the large dataset sizes we use and the inductive bias of the convolution operation~
\cite{citationNeeded}.